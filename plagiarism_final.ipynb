{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import glob\n",
    "import pandas as pds\n",
    "N = 100\n",
    "# Scikit Learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "reff = np.zeros((N,1))\n",
    "from keras import metrics\n",
    "import math\n",
    "sus =  np.zeros((N,1))\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt # this is used for the plot the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(columns=[ 'id','status'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpiando el corpus - tardó 74 minutos en limpiarse el corpus\n",
    "\n",
    "Esto solo debe correrse una vez, para no correrlo cada vez que abramos el archivo y esperar 74 mins cada vez,  decidimos guardar el resultado de un corpus limpio en el archivo \"corpus_processed.txt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\matts\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Stopwords\n",
    "nltk.download(\"stopwords\") \n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "# # Stemming --> get root of the word\n",
    "# from nltk.stem.porter import PorterStemmer \n",
    "# from nltk.stem import SnowballStemmer # best stemmer\n",
    "\n",
    "\n",
    "# # Lemmatization --> get context\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# #eliminarAcentos = lambda s: s.decode('utf-8').translate(str.maketrans(\"áàäéèëíìïòóöùúüÀÁÄÈÉËÌÍÏÒÓÖÙÚÜ\", \"aaaeeeiiiooouuuAAAEEEIIIOOOUUU\")).encode('utf-8')\n",
    "\n",
    "\n",
    "# corpus = [] \n",
    "\n",
    "# for i in list(df.loc[:,\"text\"]):\n",
    "#     # 0. Quitamos acentos:\n",
    "#     #text = eliminarAcentos(i)\n",
    "#     # 1. Quitamos todo lo que no sea una letra:\n",
    "#     text = re.sub(\"[^a-zA-Z]\", \" \", i.decode(\"utf-8\"))\n",
    "#     # 2. Todo en minúsculas:\n",
    "#     text = text.lower()\n",
    "#     # 2.1 Quitamos espacios multiples y dejamos solo uno:\n",
    "#     text = re.sub(\"[\\s]+\", \" \", text)\n",
    "\n",
    "#     # 2.2 Extra: Quitar palabras de menos de 3 letras y espacios al principio y final\n",
    "#     text = re.sub(r\"\\W*\\b\\w{1,3}\\b\", \"\", text)\n",
    "#     text = text.strip()\n",
    "\n",
    "#     # 3. Separamos oraciones para obtener puras palabras\n",
    "#     text = text.split()\n",
    "\n",
    "#     # 4. Extraer el significado detrás de cada palabra Stemming o Lemmatization y eliminar ruido\n",
    "#     #stemmer = SnowballStemmer('spanish') # Best stemmer\n",
    "#     #ps = PorterStemmer()\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#     # 4.1 Además queremos quitar palabras irrelevantes como artículos\n",
    "#     all_stopwords = stopwords.words() \n",
    "#     #all_stopwords.remove(\"palabra\") # --> para excepciones que no queramos incluir\n",
    "\n",
    "#     # 4.2 Unimos el Stemmer/Lematization para cada palabra que no esté dentro de la lista de stopwords\n",
    "#     #text = [stemmer.stem(word) for word in text if word not in set(all_stopwords)]\n",
    "#     text = [lemmatizer.lemmatize(word) for word in text if word not in set(all_stopwords)]\n",
    "#     #text = [word for word in text if word not in set(all_stopwords)]\n",
    "\n",
    "  \n",
    "#     # 5. Unir oraciones con espacios entre cada palabra\n",
    "#     text = \" \".join(text)\n",
    "#     corpus.append(text)\n",
    "\n",
    "# corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardando el código en un archivo de texto\n",
    "# filename = \"corpus_processed.txt\"  \n",
    "\n",
    "# with open(filename, \"w\") as file:\n",
    "#     for item in corpus:\n",
    "#         file.write(str(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando el corpus procesado \n",
    "df = pd.read_table(\"corpus_processed.txt\", header=None, names=[\"text\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando datos de fuente original del articulo y machine generated. Se esta omitiendo el importar el texto de los articulos porque ya tenemos el corpus procesado en \"df\" pero es importante mencionar que inicialmente se hizo el mismo para la columna \"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10021497</td>\n",
       "      <td>og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10025</td>\n",
       "      <td>og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100390</td>\n",
       "      <td>og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004070</td>\n",
       "      <td>og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004429</td>\n",
       "      <td>og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>99228</td>\n",
       "      <td>og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>9923141</td>\n",
       "      <td>og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>994456</td>\n",
       "      <td>og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>9974682</td>\n",
       "      <td>og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>999394</td>\n",
       "      <td>og</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1990 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id status\n",
       "0     10021497     og\n",
       "1        10025     og\n",
       "2       100390     og\n",
       "3      1004070     og\n",
       "4      1004429     og\n",
       "...        ...    ...\n",
       "1985     99228     og\n",
       "1986   9923141     og\n",
       "1987    994456     og\n",
       "1988   9974682     og\n",
       "1989    999394     og\n",
       "\n",
       "[1990 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#para importar datos de machine generated solo hace falta cambiar \"mg\" por \"og\" y\n",
    "folder_path = \"wikipedia_documents_test/machined/og/\"\n",
    "\n",
    "# Encontrar folder\n",
    "files = glob.glob(os.path.join(folder_path, \"*.txt\"))\n",
    "# Iterate over each txt file\n",
    "for file in files:\n",
    "  \n",
    "    # Open the PDF file\n",
    "    \n",
    "    filename = os.path.basename(file)\n",
    "    filename = filename.split('-')[0]\n",
    "    \n",
    "    txt = open(file, 'rb')\n",
    "\n",
    "    # Leer contenido de cada txt\n",
    "    content = txt.read()\n",
    "\n",
    "    txt.close()\n",
    "    \n",
    "    #se agrego incialmente content a la columna text pero se esta omitiendo ese paso ahora\n",
    "    df2.loc[len(df2)] = [ filename, \"og\"]\n",
    "    \n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10021497</td>\n",
       "      <td>og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10025</td>\n",
       "      <td>og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100390</td>\n",
       "      <td>og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004070</td>\n",
       "      <td>og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004429</td>\n",
       "      <td>og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>99228</td>\n",
       "      <td>mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>9923141</td>\n",
       "      <td>mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>994456</td>\n",
       "      <td>mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>9974682</td>\n",
       "      <td>mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>999394</td>\n",
       "      <td>mg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3980 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id status\n",
       "0     10021497     og\n",
       "1        10025     og\n",
       "2       100390     og\n",
       "3      1004070     og\n",
       "4      1004429     og\n",
       "...        ...    ...\n",
       "3975     99228     mg\n",
       "3976   9923141     mg\n",
       "3977    994456     mg\n",
       "3978   9974682     mg\n",
       "3979    999394     mg\n",
       "\n",
       "[3980 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#para importar datos de machine generated solo hace falta cambiar \"mg\" por \"og\" y\n",
    "folder_path = \"wikipedia_documents_test/machined/mg/\"\n",
    "\n",
    "# Encontrar folder\n",
    "files = glob.glob(os.path.join(folder_path, \"*.txt\"))\n",
    "# Iterate over each txt file\n",
    "for file in files:\n",
    "  \n",
    "    # Open the PDF file\n",
    "    \n",
    "    filename = os.path.basename(file)\n",
    "    filename = filename.split('-')[0]\n",
    "    \n",
    "    txt = open(file, 'rb')\n",
    "\n",
    "    # Leer contenido de cada txt\n",
    "    content = txt.read()\n",
    "\n",
    "    txt.close()\n",
    "    \n",
    "    #se agrego incialmente content a la columna text pero se esta omitiendo ese paso ahora\n",
    "    df2.loc[len(df2)] = [ filename, \"mg\"]\n",
    "    \n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(df2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que el dataset esta bien balanceado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos categorical encoding para el target a predecir ya que la red neuronal lo requiere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[\"status\"] = le.fit_transform(df[\"status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>washington state route state route short state...</td>\n",
       "      <td>10021497</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banner europe european flag flag europe offici...</td>\n",
       "      <td>10025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>creation creation formally prelature holy cros...</td>\n",
       "      <td>100390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>citadel town city osijek croatia safeguarded b...</td>\n",
       "      <td>1004070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>liam miller liam william miller february febru...</td>\n",
       "      <td>1004429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>long range desert group long range desert grou...</td>\n",
       "      <td>99228</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>vaughn jonathan stewart vaughn born march form...</td>\n",
       "      <td>9923141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>augusto bastos augusto bastos june april parag...</td>\n",
       "      <td>994456</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>trondheim airport station trondheim airport st...</td>\n",
       "      <td>9974682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>pirate caribbean dead chest pirate caribbean d...</td>\n",
       "      <td>999394</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3980 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text        id  status\n",
       "0     washington state route state route short state...  10021497       1\n",
       "1     banner europe european flag flag europe offici...     10025       1\n",
       "2     creation creation formally prelature holy cros...    100390       1\n",
       "3     citadel town city osijek croatia safeguarded b...   1004070       1\n",
       "4     liam miller liam william miller february febru...   1004429       1\n",
       "...                                                 ...       ...     ...\n",
       "3975  long range desert group long range desert grou...     99228       0\n",
       "3976  vaughn jonathan stewart vaughn born march form...   9923141       0\n",
       "3977  augusto bastos augusto bastos june april parag...    994456       0\n",
       "3978  trondheim airport station trondheim airport st...   9974682       0\n",
       "3979  pirate caribbean dead chest pirate caribbean d...    999394       0\n",
       "\n",
       "[3980 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mg = 1 , og = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos shuffle a los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clarinet clarinet musical instrument family be...</td>\n",
       "      <td>6433</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>franz burgmeier franz burgmeier born april lie...</td>\n",
       "      <td>11471512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chartjackers chartjackers british narrative ar...</td>\n",
       "      <td>25154219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>violent wind tropical cyclone twister caused r...</td>\n",
       "      <td>36619573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>leccinum rugosiceps leccinum rugosiceps common...</td>\n",
       "      <td>45459609</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>returning home diddy dirty money melody return...</td>\n",
       "      <td>30010737</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>euro note euro note esteem euro banknote utili...</td>\n",
       "      <td>24190481</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>uncanny tale canadian pulp magazine uncanny ta...</td>\n",
       "      <td>15738365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>krista branch krista branch american vocalist ...</td>\n",
       "      <td>33562778</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>atlantic hurricane season atlantic hurricane s...</td>\n",
       "      <td>802074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3980 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text        id  status\n",
       "0     clarinet clarinet musical instrument family be...      6433       0\n",
       "1     franz burgmeier franz burgmeier born april lie...  11471512       0\n",
       "2     chartjackers chartjackers british narrative ar...  25154219       1\n",
       "3     violent wind tropical cyclone twister caused r...  36619573       1\n",
       "4     leccinum rugosiceps leccinum rugosiceps common...  45459609       0\n",
       "...                                                 ...       ...     ...\n",
       "3975  returning home diddy dirty money melody return...  30010737       1\n",
       "3976  euro note euro note esteem euro banknote utili...  24190481       1\n",
       "3977  uncanny tale canadian pulp magazine uncanny ta...  15738365       0\n",
       "3978  krista branch krista branch american vocalist ...  33562778       1\n",
       "3979  atlantic hurricane season atlantic hurricane s...    802074       0\n",
       "\n",
       "[3980 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizamos palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(df[['text', 'id']].apply(lambda x: ' '.join(x), axis=1)).toarray()\n",
    "y = df[\"status\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clarinet clarinet musical instrument family be...</td>\n",
       "      <td>6433</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>franz burgmeier franz burgmeier born april lie...</td>\n",
       "      <td>11471512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chartjackers chartjackers british narrative ar...</td>\n",
       "      <td>25154219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>violent wind tropical cyclone twister caused r...</td>\n",
       "      <td>36619573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>leccinum rugosiceps leccinum rugosiceps common...</td>\n",
       "      <td>45459609</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>returning home diddy dirty money melody return...</td>\n",
       "      <td>30010737</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>euro note euro note esteem euro banknote utili...</td>\n",
       "      <td>24190481</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>uncanny tale canadian pulp magazine uncanny ta...</td>\n",
       "      <td>15738365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>krista branch krista branch american vocalist ...</td>\n",
       "      <td>33562778</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>atlantic hurricane season atlantic hurricane s...</td>\n",
       "      <td>802074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3980 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text        id  status\n",
       "0     clarinet clarinet musical instrument family be...      6433       0\n",
       "1     franz burgmeier franz burgmeier born april lie...  11471512       0\n",
       "2     chartjackers chartjackers british narrative ar...  25154219       1\n",
       "3     violent wind tropical cyclone twister caused r...  36619573       1\n",
       "4     leccinum rugosiceps leccinum rugosiceps common...  45459609       0\n",
       "...                                                 ...       ...     ...\n",
       "3975  returning home diddy dirty money melody return...  30010737       1\n",
       "3976  euro note euro note esteem euro banknote utili...  24190481       1\n",
       "3977  uncanny tale canadian pulp magazine uncanny ta...  15738365       0\n",
       "3978  krista branch krista branch american vocalist ...  33562778       1\n",
       "3979  atlantic hurricane season atlantic hurricane s...    802074       0\n",
       "\n",
       "[3980 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train y test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=29)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de la RNN\n",
    "\n",
    "Una red neuronal artificial (ANN, por sus siglas en inglés) es un modelo matemático y computacional que se inspira en la estructura y el funcionamiento del cerebro humano para procesar información. Consiste en un conjunto de nodos interconectados, conocidos como neuronas artificiales, que reciben una entrada de datos, realizan un cálculo y producen una salida.\n",
    "\n",
    "Cada neurona en una ANN tiene un conjunto de entradas ponderadas que se suman y se pasan a través de una función de activación no lineal para generar la salida de la neurona. La red está organizada en capas, donde cada capa se compone de múltiples neuronas. La primera capa se llama capa de entrada, la última capa se llama capa de salida, y las capas intermedias se llaman capas ocultas.\n",
    "\n",
    "El proceso de entrenamiento de una ANN implica ajustar los pesos y los sesgos de las conexiones entre las neuronas para minimizar una función de pérdida. Esto se realiza utilizando técnicas de aprendizaje supervisado o no supervisado, en función del tipo de problema que se esté abordando.\n",
    "\n",
    "En este caso usaremos las herramientas de Tensor Flow para poder crear nuestra ANN\n",
    "\n",
    "-  'units' se refiere al número de neuronas en la capa densa que se está agregando a la red neuronal. Es decir, esta capa tendrá 200 neuronas en total. El número de unidades en una capa densa es un parámetro que se puede ajustar para controlar la complejidad y la capacidad de aprendizaje de la red neuronal.  units se refiere al número de neuronas en la capa densa que se está agregando a la red neuronal. Es decir, esta capa tendrá 200 neuronas en total. El número de unidades en una capa densa es un parámetro que se puede ajustar para controlar la complejidad y la capacidad de aprendizaje de la red neuronal.\n",
    "\n",
    "- 'activation'  se refiere a la función de activación que se utilizará en la capa densa que se está agregando a la red neuronal.\n",
    "\n",
    "    - La función de activación es una función matemática que se aplica a la salida de cada neurona en una capa para introducir no linealidad en la red neuronal. La función relu (unidad lineal rectificada) es una función de activación comúnmente utilizada que retorna 0 si la entrada es negativa y la entrada misma si es positiva o cero.\n",
    "\n",
    "    - La función relu se usa a menudo porque puede ayudar a prevenir el problema de la desaparición del gradiente en el entrenamiento de redes neuronales profundas, lo que puede ocurrir cuando se usan funciones de activación que tienen gradientes muy pequeños en ciertas regiones.\n",
    "\n",
    "    - La función Softmax es una función de activación comúnmente utilizada en la capa de salida de una red neuronal para producir una distribución de probabilidad sobre varias clases. La función Softmax es especialmente útil en problemas de clasificación multiclase, donde se desea predecir la probabilidad de pertenencia a varias clases diferentes. Por ejemplo, en una red neuronal para clasificar imágenes, la función Softmax puede utilizarse para producir una distribución de probabilidad sobre varias categorías de objetos (por ejemplo, gatos, perros, aviones, etc.) basándose en las características de la imagen de entrada.\n",
    "\n",
    "    - Existen otras funciones de activación comunes, como la función sigmoid, la función tanh, y la función softmax, cada una de las cuales se utiliza para diferentes propósitos según el problema específico de la red neuronal.\n",
    "\n",
    "- 'optimizer' se refiere a la función de optimización para ajustar los pesos conforme a la taza de aprendizaje que se utilizará en la capa densa que se está agregando a la red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x19552b4ce10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "ann = tf.keras.models.Sequential()\n",
    "ann.add(tf.keras.layers.Dense(units=200, activation=\"relu\"))\n",
    "ann.add(tf.keras.layers.Dense(units=200, activation=\"relu\")) \n",
    "ann.add(tf.keras.layers.Dense(units=200, activation=\"relu\"))\n",
    "ann.add(tf.keras.layers.Dense(units=2, activation=\"softmax\"))\n",
    "ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se usa sparse_categorical_crossentropy\n",
    "ann.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "70/70 [==============================] - 14s 178ms/step - loss: 0.1534 - accuracy: 0.9789 - val_loss: 0.0069 - val_accuracy: 0.9982\n",
      "Epoch 2/50\n",
      "70/70 [==============================] - 11s 163ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0179 - val_accuracy: 0.9928\n",
      "Epoch 3/50\n",
      "70/70 [==============================] - 11s 162ms/step - loss: 7.0387e-04 - accuracy: 0.9996 - val_loss: 0.0109 - val_accuracy: 0.9946\n",
      "Epoch 4/50\n",
      "70/70 [==============================] - 12s 166ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.0057 - val_accuracy: 0.9982\n",
      "peak memory: 7194.84 MiB, increment: 580.71 MiB\n",
      "Time taken to fit the model: 51.474650382995605 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import memory_profiler\n",
    "start_time = time.time() \n",
    "%load_ext memory_profiler\n",
    "%memit ann.fit(x=X_train, y=y_train, batch_size=32, epochs=50, validation_split=0.2, callbacks=[early_stopping])\n",
    "end_time = time.time()\n",
    "print(f\"Time taken to fit the model: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9992\n",
      "Test accuracy: 0.999162495136261\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = ann.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quisieramos guardar los pesos del modelo para no reentrenar el modelo sería de esta manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m k\n",
      "\u001b[1;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
